# -*- coding: utf-8 -*-
"""
Created on Tue May 18 16:24:58 2021

@author: Jonathas Haniel

PINN with navier-stokes loss functions

using tensorflow 2.5.0
using tf_siren for tf2.0 -> pip install --upgrade tf_siren
"""
import tensorflow as tf
from tf_siren import SinusodialRepresentationDense
import numpy as np
import time
from datetime import datetime


class PINN(object):
  def __init__(self, optimizer, X_f, logger, rho = 1, mu = 0.0001, diff ='AD', diff_delta = 0.125, Steady = False):
    self.mu = mu
    self.rho = rho
    self.optimizer = optimizer
    self.logger = logger
    self.dtype = tf.float32
    self.steady  = Steady
    self.diff_method = diff
    self.X_pinn_train = tf.convert_to_tensor(X_f, dtype=self.dtype)
    self.X_pinn_train_x = self.X_pinn_train[:, 0:1]
    self.X_pinn_train_y = self.X_pinn_train[:, 1:2]
    self.X_pinn_train_t = tf.convert_to_tensor([], dtype=self.dtype)
    if not self.steady:
      self.X_pinn_train_t = self.X_pinn_train[:, 2:3]
    self.X_outside = tf.convert_to_tensor([], dtype=self.dtype)
    self.losses = tf.Variable([0,0,0,0,0,0], trainable=False, dtype=self.dtype)
    self.DELTA = tf.constant([diff_delta],dtype=self.dtype)  #delta for numeric differentiation (remember x,y,and t are normalized [-1,+1])
    
    self.start_dynamic_weight()
    
  def Foward(self,layers,activation):
    # Keras model, defined by layers
    self.model = tf.keras.Sequential()
    self.model.add(tf.keras.layers.InputLayer(input_shape=(layers[0],)))
    for width in layers[1:]:
      if not width == layers[-1]:
        self.model.add(tf.keras.layers.Dense(
            width, activation=activation,
            kernel_initializer='glorot_normal',
            # kernel_constraint= tf.keras.constraints.MinMaxNorm(min_value=-4.0, max_value=4.0),
            # kernel_regularizer=tf.keras.regularizers.l2(0.001)
            ))
      else:
        self.model.add(tf.keras.layers.Dense(
            width, activation=activation,
            kernel_initializer='glorot_normal'))
        
  def Foward_Siren(self,layers,activation):
    # Keras model, using Siren activation: https://github.com/titu1994/tf_SIREN
    input = tf.keras.Input(shape=(layers[0],), name='input (x,y,t)')
    u = 0
    for width in layers[1:-1]:
      if  u <  1:
        x = input
      u += 1
      x = SinusodialRepresentationDense(width,activation='sine',w0=1.0)(x)
    output = tf.keras.layers.Dense(layers[-1], activation=activation,
                              kernel_initializer='glorot_normal')(x)
    self.model = tf.keras.Model(inputs=[input], outputs=[output])

  def Multi_channel_foward(self,layers,activation):
    input = tf.keras.Input(shape=(layers[0][0],), dtype=self.dtype, name='input (x,y,t)')
    x = tf.keras.layers.Dense(layers[0][1], activation=activation,
                              kernel_initializer='glorot_normal')(input)
    y = tf.keras.layers.Dense(layers[1][1], activation=activation,
                              kernel_initializer='glorot_normal')(input)
    z = tf.keras.layers.Dense(layers[2][1], activation=activation,
                              kernel_initializer='glorot_normal')(input)
    for width in layers[0][2:-1]:
      x = tf.keras.layers.Dense(width, activation=activation,
                                kernel_initializer='glorot_normal')(x)
    for width in layers[1][2:-1]:
      y = tf.keras.layers.Dense(width, activation=activation,
                                kernel_initializer='glorot_normal')(y)
    for width in layers[2][2:-1]:
      z = tf.keras.layers.Dense(width, activation=activation,
                                kernel_initializer='glorot_normal')(z)
    output0 = tf.keras.layers.Dense(layers[0][-1], activation= activation,
                                    kernel_initializer='glorot_normal', name='u')(x)
    output1 = tf.keras.layers.Dense(layers[0][-1], activation= activation,
                                    kernel_initializer='glorot_normal', name='v')(y)
    output2 = tf.keras.layers.Dense(layers[0][-1], activation= activation,
                                    kernel_initializer='glorot_normal', name='p')(z)
    output = tf.keras.layers.concatenate([output0,output1,output2])
    self.model = tf.keras.Model(inputs=[input], outputs=[output])

  def Foward_residual(self,layers,activation):

    input = tf.keras.Input(shape=(layers[0],), name='input (x,y,t)')
    u = 0
    for width in layers[1:-1]:
      if  u <  1:
        x = input
      u += 1
      x = tf.keras.layers.Dense(width, activation=activation,
                              kernel_initializer='glorot_normal')(x)
      x1 = tf.keras.layers.Dense(width, activation=activation,
                              kernel_initializer='glorot_normal')(x)
      x1 = tf.keras.layers.Dense(width,kernel_initializer='glorot_normal')(x1)
      x = tf.keras.layers.Add()([x,x1])
      x = activation(x)
    output = tf.keras.layers.Dense(layers[-1], activation=activation,
                              kernel_initializer='glorot_normal')(x)
    self.model = tf.keras.Model(inputs=[input], outputs=[output])

  def Multi_channel_foward_residual(self,layers,activation):
    input = tf.keras.Input(shape=(layers[0][0],), name='input (x,y,t)')
    u = 0
    for width in layers[0][1:-1]:
      if  u <  1:
        x = input
      u += 1
      x = tf.keras.layers.Dense(width, activation=activation,
                              kernel_initializer='glorot_normal')(x)
      x1 = tf.keras.layers.Dense(width, activation=activation,
                              kernel_initializer='glorot_normal')(x)
      x1 = tf.keras.layers.Dense(width,kernel_initializer='glorot_normal')(x1)
      x = tf.keras.layers.Add()([x,x1])
      x = activation(x)
    u = 0
    for width in layers[1][1:-1]:
      if  u <  1:
        y = input
      u += 1
      y = tf.keras.layers.Dense(width, activation=activation,
                              kernel_initializer='glorot_normal')(y)
      y1 = tf.keras.layers.Dense(width, activation=activation,
                              kernel_initializer='glorot_normal')(y)
      y1 = tf.keras.layers.Dense(width,kernel_initializer='glorot_normal')(y1)
      y = tf.keras.layers.Add()([y,y1])
      y = activation(y)
    u = 0
    for width in layers[2][1:-1]:
      if  u <  1:
        z = input
      u += 1
      z = tf.keras.layers.Dense(width, activation=activation,
                              kernel_initializer='glorot_normal')(z)
      z1 = tf.keras.layers.Dense(width, activation=activation,
                              kernel_initializer='glorot_normal')(z)
      z1 = tf.keras.layers.Dense(width,kernel_initializer='glorot_normal')(z1)
      z = tf.keras.layers.Add()([z,z1])
      z = activation(z)

    output0 = tf.keras.layers.Dense(layers[0][-1], activation= activation,
                                    kernel_initializer='glorot_normal', name='u')(x)
    output1 = tf.keras.layers.Dense(layers[0][-1], activation= activation,
                                    kernel_initializer='glorot_normal', name='v')(y)
    output2 = tf.keras.layers.Dense(layers[0][-1], activation= activation,
                                    kernel_initializer='glorot_normal', name='p')(z)
    output = tf.keras.layers.concatenate([output0,output1,output2])
    self.model = tf.keras.Model(inputs=[input], outputs=[output])

    dot_img_file = '.\model_plot_test.png'
    tf.keras.utils.plot_model(self.model, to_file=dot_img_file, show_shapes=True) 
    
    
  # calculate loss gradients to update weights and bias
  @tf.function
  def f_grad(self):
    
    ##this double gradient tape make everything slow to compile 
    with tf.GradientTape() as tape:
      loss_value = self.f_loss()
    return loss_value, tape.gradient(loss_value, self.model.trainable_variables)

  # Defining custom loss
  @tf.function
  def f_loss(self):
    
    #dynamic weights
    if self.dynamic_weight_method == 'balance':
      loss = self.DW_balance(self.Calculate_separate_losses())
    elif self.dynamic_weight_method == 'relobralo':
      loss = self.DW_ReLoBRaLo(self.Calculate_separate_losses())
    elif self.dynamic_weight_method == 'LR_annealing':
      loss = self.LR_Annealing()      
    else:
      loss = tf.reduce_sum(self.Calculate_separate_losses())  
    return loss
  
  @tf.function
  def Calculate_separate_losses(self):
    # verify and calculate loss data and/or boundary
    if self.Y_bd_vel.shape[0]>0:
      loss_bd_vel = self.Y_bd_vel - \
        tf.cast(self.model(self.X_bd_vel,training=True)[:, 0:2], self.dtype)
    else:
      loss_bd_vel =tf.constant(0, dtype = self.dtype)
    if self.X_outside.shape[0] > 0:
      loss_out_vel = tf.cast(self.model(self.X_outside,training=True)[:, 0:2], self.dtype)
    else:
      loss_out_vel =tf.constant(0, dtype = self.dtype)
    
    if self.Y_bd_pre.shape[0]>0:
      loss_bd_pre = self.Y_bd_pre - \
        tf.cast(self.model(self.X_bd_pre,training=True)[:, 2:3], self.dtype)
    else:
      loss_bd_pre =tf.constant(0, dtype = self.dtype)

    if self.Y_data.shape[0]>0:
      if self.Y_data.shape[1]==3:
        loss_data = self.Y_data - tf.cast(self.model(self.X_data,training=True), self.dtype)
      elif self.Y_data.shape[1]==2:
        loss_data = self.Y_data[:,0:2] - tf.cast(self.model(self.X_data,training=True), self.dtype)[:,0:2]
    else:
      loss_data = tf.constant(0, dtype = self.dtype)
    # calculate loss by Navier-Stokes
    loss_momentum, loss_mass = self.Navier_Stokes_Residuals()

# error =  0.035430223
    l1 = tf.math.scalar_mul(self.pinn_w[0],tf.reduce_mean(tf.square(loss_momentum)))
    l2 = tf.math.scalar_mul(self.pinn_w[1],tf.reduce_mean(tf.square(loss_mass)))
    l3 = tf.math.scalar_mul(self.pinn_w[2],tf.reduce_mean(tf.square(loss_bd_vel)))
    l4 = tf.math.scalar_mul(self.pinn_w[3],tf.reduce_mean(tf.square(loss_bd_pre)))
    l5 = tf.math.scalar_mul(self.pinn_w[4],tf.reduce_mean(tf.square(loss_data)))
    l6 = tf.math.scalar_mul(self.pinn_w[5],tf.reduce_mean(tf.square(loss_out_vel)))
    
# error =  0.035099596    
    # l1 = tf.math.scalar_mul(self.pinn_w[0],tf.reduce_mean(tf.math.log(tf.math.cosh(loss_momentum))))
    # l2 = tf.math.scalar_mul(self.pinn_w[1],tf.reduce_mean(tf.math.log(tf.math.cosh(loss_mass))))
    # l3 = tf.math.scalar_mul(self.pinn_w[2],tf.reduce_mean(tf.math.square(loss_bd_vel)))
    # l4 = tf.math.scalar_mul(self.pinn_w[3],tf.reduce_mean(tf.math.square(loss_bd_pre)))
    # l5 = tf.math.scalar_mul(self.pinn_w[4],tf.reduce_mean(tf.math.square(loss_data)))
    # l6 = tf.math.scalar_mul(self.pinn_w[5],tf.reduce_mean(tf.math.square(loss_out_vel)))
    self.losses.assign([l1, l2, l3, l4 ,l5, l6])
    
    return [l1, l2, l3, l4 ,l5, l6]
  
  @tf.function
  def Navier_Stokes_Residuals(self):
    #chose differentiation method
    if self.diff_method == 'ND1':
      Diff_scheme = self.ND_First_Upwind
    elif self.diff_method == 'ND2':
      Diff_scheme = self.ND_Second_Upwind
    elif self.diff_method == 'AD':
      Diff_scheme = self.AD_scheme
    elif self.diff_method == 'CAN':
      Diff_scheme = self.CAN_scheme
    else:
      Diff_scheme =  self.AD_scheme
      
    u,v,p,u_x,u_y,u_t,v_x,v_y,v_t,p_x,p_y,u_xx,u_yy,v_xx,v_yy = Diff_scheme() 
    # NAVIER-STOKES residuals
    loss_x = self.rho * (u_t + u*u_x + v*u_y) + p_x - self.mu*(u_xx + u_yy )
    loss_y = self.rho * (v_t + u*v_x + v*v_y) + p_y - self.mu*(v_xx + v_yy )
    # loss_x = (u_t + u*u_x + v*u_y) + p_x - (1/RE)*(u_xx + u_yy )
    # loss_y = (v_t + u*v_x + v*v_y) + p_y - (1/RE)*(v_xx + v_yy )
    loss_mass = u_x + v_y
    #loss_momentum = (loss_x + loss_y)   'can be weighted to balance components residual'
    return (loss_x + loss_y), loss_mass
    
  
  # Models of PINN loss N-pinn
  @tf.function
  def ND_Second_Upwind(self):
    # Using numerical diferentiation 2 order upwind for velocity and pressure, and 1 order upwind for time
    
    # Packing the inputs together 
    if not self.steady:
      X_f = tf.stack([self.x_batch[:,0], self.y_batch[:,0], self.t_batch[:,0]], axis=1)
      X_f_minusDELTAx = tf.stack([self.x_batch[:,0]-self.DELTA, self.y_batch[:,0], self.t_batch[:,0]], axis=1)
      X_f_minusDELTAy = tf.stack([self.x_batch[:,0], self.y_batch[:,0]-self.DELTA, self.t_batch[:,0]], axis=1)
      X_f_minus2DELTAx = tf.stack([self.x_batch[:,0]-(2.*self.DELTA), self.y_batch[:,0], self.t_batch[:,0]], axis=1)
      X_f_minus2DELTAy = tf.stack([self.x_batch[:,0], self.y_batch[:,0]-(2.*self.DELTA), self.t_batch[:,0]], axis=1)
      X_f_minus3DELTAx = tf.stack([self.x_batch[:,0]-(3.*self.DELTA), self.y_batch[:,0], self.t_batch[:,0]], axis=1)
      X_f_minus3DELTAy = tf.stack([self.x_batch[:,0], self.y_batch[:,0]-(3.*self.DELTA), self.t_batch[:,0]], axis=1)
      X_f_minusDELTAt = tf.stack([self.x_batch[:,0], self.y_batch[:,0], self.t_batch[:,0]-self.DELTA], axis=1)
    else:
      X_f = tf.stack([self.x_batch[:,0], self.y_batch[:,0]], axis=1)
      X_f_minusDELTAx = tf.stack([self.x_batch[:,0]-self.DELTA, self.y_batch[:,0]], axis=1)
      X_f_minusDELTAy = tf.stack([self.x_batch[:,0], self.y_batch[:,0]-self.DELTA], axis=1)
      X_f_minus2DELTAx = tf.stack([self.x_batch[:,0]-(2.*self.DELTA), self.y_batch[:,0]], axis=1)
      X_f_minus2DELTAy = tf.stack([self.x_batch[:,0], self.y_batch[:,0]-(2.*self.DELTA)], axis=1)
      X_f_minus3DELTAx = tf.stack([self.x_batch[:,0]-(3.*self.DELTA), self.y_batch[:,0]], axis=1)
      X_f_minus3DELTAy = tf.stack([self.x_batch[:,0], self.y_batch[:,0]-(3.*self.DELTA)], axis=1)
      
    # Getting deslocaded prediction
    u,v,p = self.Sliced_Predict(X_f)
    u_deltax, v_deltax, p_deltax = self.Sliced_Predict(X_f_minusDELTAx)
    u_deltay, v_deltay, p_deltay = self.Sliced_Predict(X_f_minusDELTAy)
    u_2deltax, v_2deltax, p_2deltax =self.Sliced_Predict(X_f_minus2DELTAx)
    u_2deltay, v_2deltay, p_2deltay =self.Sliced_Predict(X_f_minus2DELTAy)
    u_3deltax, v_3deltax, p_3deltax =self.Sliced_Predict(X_f_minus3DELTAx)
    u_3deltay, v_3deltay, p_3deltay =self.Sliced_Predict(X_f_minus3DELTAy)
    
    # Second-order upwind (backward difference)  O(\Deltax^2)
    u_x = (3.*u - 4.*u_deltax + u_2deltax)/(2.*self.DELTA)
    v_x = (3.*v - 4.*v_deltax + v_2deltax)/(2.*self.DELTA)
    u_y = (3.*u - 4.*u_deltay + u_2deltay)/(2.*self.DELTA) 
    v_y = (3.*v - 4.*v_deltay + v_2deltay)/(2.*self.DELTA)
    p_x = (3.*p - 4.*p_deltax + p_2deltax)/(2.*self.DELTA)
    p_y = (3.*p - 4.*p_deltay + p_2deltay)/(2.*self.DELTA)
      # Getting the second other derivatives
    u_xx = (2.*u - 5.*u_deltax + 4.*u_2deltax - u_3deltax)/(self.DELTA**3)
    u_yy = (2.*u - 5.*u_deltay + 4.*u_2deltay - u_3deltay)/(self.DELTA**3)
    v_xx = (2.*v - 5.*v_deltax + 4.*v_2deltax - v_3deltax)/(self.DELTA**3)
    v_yy = (2.*v - 5.*v_deltay + 4.*v_2deltay - v_3deltay)/(self.DELTA**3)

    if not self.steady:
      #first-order upwind (backward difference)  O(\Deltax^1)
      u_deltat, v_deltat, _ = self.Sliced_Predict(X_f_minusDELTAt)
      u_t = (u-u_deltat)/self.DELTA 
      v_t = (v-v_deltat)/self.DELTA 
    else:
      u_t = 0.
      v_t = 0.
 
    return u,v,p,u_x,u_y,u_t,v_x,v_y,v_t,p_x,p_y,u_xx,u_yy,v_xx,v_yy
  
  # Models of PINN loss N-pinn
  @tf.function
  def ND_First_Upwind(self):
    # Using numerical diferentiation 1 order upwind for velocity and pressure, and 1 order upwind for time
    
    # Packing the inputs together 
    if not self.steady:
      X_f = tf.stack([self.x_batch[:,0], self.y_batch[:,0], self.t_batch[:,0]], axis=1)
      X_f_minusDELTAx = tf.stack([self.x_batch[:,0]-self.DELTA, self.y_batch[:,0], self.t_batch[:,0]], axis=1)
      X_f_minusDELTAy = tf.stack([self.x_batch[:,0], self.y_batch[:,0]-self.DELTA, self.t_batch[:,0]], axis=1)
      X_f_minus2DELTAx = tf.stack([self.x_batch[:,0]-(2.*self.DELTA), self.y_batch[:,0], self.t_batch[:,0]], axis=1)
      X_f_minus2DELTAy = tf.stack([self.x_batch[:,0], self.y_batch[:,0]-(2.*self.DELTA), self.t_batch[:,0]], axis=1)
      X_f_minusDELTAt = tf.stack([self.x_batch[:,0], self.y_batch[:,0], self.t_batch[:,0]-self.DELTA], axis=1)
    else:
      X_f = tf.stack([self.x_batch[:,0], self.y_batch[:,0]], axis=1)
      X_f_minusDELTAx = tf.stack([self.x_batch[:,0]-self.DELTA, self.y_batch[:,0]], axis=1)
      X_f_minusDELTAy = tf.stack([self.x_batch[:,0], self.y_batch[:,0]-self.DELTA], axis=1)
      X_f_minus2DELTAx = tf.stack([self.x_batch[:,0]-(2.*self.DELTA), self.y_batch[:,0]], axis=1)
      X_f_minus2DELTAy = tf.stack([self.x_batch[:,0], self.y_batch[:,0]-(2.*self.DELTA)], axis=1)

      
    # Getting deslocaded prediction
    u,v,p = self.Sliced_Predict(X_f)
    u_deltax, v_deltax, p_deltax = self.Sliced_Predict(X_f_minusDELTAx)
    u_deltay, v_deltay, p_deltay = self.Sliced_Predict(X_f_minusDELTAy)
    u_2deltax, v_2deltax, p_2deltax =self.Sliced_Predict(X_f_minus2DELTAx)
    u_2deltay, v_2deltay, p_2deltay =self.Sliced_Predict(X_f_minus2DELTAy)
    
    # first-order upwind (backward difference)  O(\Deltax^2)
    u_x = (u -u_deltax)/self.DELTA
    v_x = (v - v_deltax)/self.DELTA
    u_y = (u - u_deltay)/self.DELTA 
    v_y = (v - v_deltay)/self.DELTA
    p_x = (3.*p - 4.*p_deltax + p_2deltax)/(2.*self.DELTA)
    p_y = (3.*p - 4.*p_deltay + p_2deltay)/(2.*self.DELTA)
      # Getting the second other derivatives
    u_xx = (u - 2.*u_deltax + u_2deltax)/(self.DELTA**2)
    u_yy = (u - 2.*u_deltay + u_2deltay)/(self.DELTA**2)
    v_xx = (v - 2.*v_deltax + v_2deltax)/(self.DELTA**2)
    v_yy = (v - 2.*v_deltay + v_2deltay)/(self.DELTA**2)

    if not self.steady:
      #first-order upwind (backward difference)  O(\Deltax^1)
      u_deltat, v_deltat, _ = self.Sliced_Predict(X_f_minusDELTAt)
      u_t = (u-u_deltat)/self.DELTA 
      v_t = (v-v_deltat)/self.DELTA 
    else:
      u_t = 0.
      v_t = 0.

    return u,v,p,u_x,u_y,u_t,v_x,v_y,v_t,p_x,p_y,u_xx,u_yy,v_xx,v_yy
  
  @tf.function
  def AD_scheme(self):
    # Using the new GradientTape paradigm of TF2.0,
    # which keeps track of operations to get the gradient at runtime
    with tf.GradientTape(persistent=True) as tape3:
      tape3.watch(self.x_batch)
      tape3.watch(self.y_batch)
      
      with tf.GradientTape(persistent=True) as tape4:
        # Watching the three inputs we’ll need later, x , y and t
        tape4.watch(self.x_batch)
        tape4.watch(self.y_batch)
        if not self.steady:
          tape4.watch(self.t_batch)
          X_f = tf.stack([self.x_batch[:,0], self.y_batch[:,0], self.t_batch[:,0]], axis=1)
        else:
          # Packing together the inputs
          X_f = tf.stack([self.x_batch[:,0], self.y_batch[:,0]], axis=1)
  
        # Getting the prediction
        Pred =  tf.cast(self.model(X_f,training=True), self.dtype)
        u = tf.slice(Pred,[0,0],[-1,1])
        v = tf.slice(Pred,[0,1],[-1,1])
        p = tf.slice(Pred,[0,2],[-1,1])
   
      u_x = tape4.gradient(u, self.x_batch)
      v_x = tape4.gradient(v, self.x_batch)
      u_y = tape4.gradient(u, self.y_batch)
      v_y = tape4.gradient(v, self.y_batch)
      if not self.steady:
        u_t = tape4.gradient(u, self.t_batch)
        v_t = tape4.gradient(v, self.t_batch)
      else:
        u_t = 0.
        v_t = 0.
    
    # Getting the other derivatives
    u_xx = tape3.gradient(u_x, self.x_batch)
    u_yy = tape3.gradient(u_y, self.y_batch)
    v_xx = tape3.gradient(v_x, self.x_batch)
    v_yy = tape3.gradient(v_y, self.y_batch)
    p_x = tape3.gradient(p, self.x_batch)
    p_y = tape3.gradient(p, self.y_batch)
        
    del tape3, tape4

    return u,v,p,u_x,u_y,u_t,v_x,v_y,v_t,p_x,p_y,u_xx,u_yy,v_xx,v_yy
  
  @tf.function
  def CAN_scheme(self):
    # Using the new GradientTape paradigm of TF2.0,
    # which keeps track of operations to get the gradient at runtime
    with tf.GradientTape(persistent=True) as tape3:
      x_batch_minusDELTA = self.x_batch[:,0]-self.DELTA
      x_batch_minus2DELTA = self.x_batch[:,0]-(2.*self.DELTA)
      x_batch_plusDELTA = self.x_batch[:,0]+self.DELTA
      y_batch_minusDELTA = self.y_batch[:,0]-self.DELTA
      y_batch_minus2DELTA = self.y_batch[:,0]-(2.*self.DELTA)
      y_batch_plusDELTA = self.y_batch[:,0]+self.DELTA
      tape3.watch(self.x_batch)
      tape3.watch(self.y_batch)
      tape3.watch(x_batch_minusDELTA)
      tape3.watch(y_batch_minusDELTA)
      tape3.watch(x_batch_plusDELTA)
      tape3.watch(y_batch_plusDELTA)
      
      with tf.GradientTape(persistent=True) as tape4:
        # Watching the three inputs we’ll need later, x , y and t
        tape4.watch(self.x_batch)
        tape4.watch(self.y_batch)
        tape4.watch(x_batch_minusDELTA)
        tape4.watch(y_batch_minusDELTA)
        
        if not self.steady:
          t_batch_minusDELTA = self.t_batch[:,0]-self.DELTA
          tape4.watch(self.t_batch)
          tape4.watch(t_batch_minusDELTA)
          X_f = tf.stack([self.x_batch[:,0], self.y_batch[:,0], self.t_batch[:,0]], axis=1)
          X_f_minusDELTAx = tf.stack([x_batch_minusDELTA, self.y_batch[:,0], self.t_batch[:,0]], axis=1)
          X_f_minusDELTAy = tf.stack([self.x_batch[:,0], y_batch_minusDELTA, self.t_batch[:,0]], axis=1)
          X_f_minus2DELTAx = tf.stack([x_batch_minus2DELTA, self.y_batch[:,0], self.t_batch[:,0]], axis=1)
          X_f_minus2DELTAy = tf.stack([self.x_batch[:,0], y_batch_minus2DELTA, self.t_batch[:,0]], axis=1)
          X_f_plusDELTAx = tf.stack([x_batch_plusDELTA, self.y_batch[:,0], self.t_batch[:,0]], axis=1)
          X_f_plusDELTAy = tf.stack([self.x_batch[:,0], y_batch_plusDELTA, self.t_batch[:,0]], axis=1)
          X_f_minusDELTAt = tf.stack([self.x_batch[:,0], self.y_batch[:,0], t_batch_minusDELTA], axis=1)
          u_deltat, v_deltat, _ = self.Sliced_Predict(X_f_minusDELTAt)
        else:
          X_f = tf.stack([self.x_batch[:,0], self.y_batch[:,0]], axis=1)
          X_f_minusDELTAx = tf.stack([x_batch_minusDELTA, self.y_batch[:,0]], axis=1)
          X_f_minusDELTAy = tf.stack([self.x_batch[:,0], y_batch_minusDELTA], axis=1)
          X_f_minus2DELTAx = tf.stack([x_batch_minus2DELTA, self.y_batch[:,0]], axis=1)
          X_f_minus2DELTAy = tf.stack([self.x_batch[:,0], y_batch_minus2DELTA], axis=1)
          X_f_plusDELTAx = tf.stack([x_batch_plusDELTA, self.y_batch[:,0]], axis=1)
          X_f_plusDELTAy = tf.stack([self.x_batch[:,0], y_batch_plusDELTA], axis=1)
  
        # Getting the prediction
        # Getting deslocaded prediction
        u,v,p = self.Sliced_Predict(X_f)
        u_deltax, v_deltax, p_deltax = self.Sliced_Predict(X_f_minusDELTAx)
        u_deltay, v_deltay, p_deltay = self.Sliced_Predict(X_f_minusDELTAy)
        u_2deltax, v_2deltax, _ =self.Sliced_Predict(X_f_minus2DELTAx)
        u_2deltay, v_2deltay, _ =self.Sliced_Predict(X_f_minus2DELTAy)
        _, _, p_pdeltax = self.Sliced_Predict(X_f_plusDELTAx)
        _, _, p_pdeltay = self.Sliced_Predict(X_f_plusDELTAy)

      ad_u_x = tape4.gradient(u, self.x_batch)
      ad_v_x = tape4.gradient(v, self.x_batch)
      ad_u_y = tape4.gradient(u, self.y_batch)
      ad_v_y = tape4.gradient(v, self.y_batch)
      ad_u_x_delta = tape4.gradient(u_deltax, x_batch_minusDELTA)
      ad_v_x_delta = tape4.gradient(v_deltax, x_batch_minusDELTA)
      ad_u_y_delta = tape4.gradient(u_deltay, y_batch_minusDELTA)
      ad_v_y_delta = tape4.gradient(v_deltay, y_batch_minusDELTA)
      
      u_x = ((u - u_deltax)/self.DELTA) + (ad_u_x - ad_u_x_delta)/2.
      v_x = ((v - v_deltax)/self.DELTA) + (ad_v_x - ad_v_x_delta)/2.
      u_y = ((u - u_deltay)/self.DELTA) + (ad_u_y - ad_u_y_delta)/2.
      v_y = ((v - v_deltay)/self.DELTA) + (ad_v_y - ad_v_y_delta)/2.
      if not self.steady:
        u_t = ((u-u_deltat)/self.DELTA) + (tape4.gradient(u, self.t_batch)-tape4.gradient(u_deltat, t_batch_minusDELTA))/2.
        v_t = ((v-v_deltat)/self.DELTA) + (tape4.gradient(v, self.t_batch)-tape4.gradient(v_deltat, t_batch_minusDELTA))/2.
      else:
        u_t = 0.
        v_t = 0.
    
    # Getting the other derivatives
    u_xx = ((u - 2.0*u_deltax + u_2deltax)/(self.DELTA**2)) + (tape3.gradient(ad_u_x, self.x_batch)-tape3.gradient(ad_u_x_delta, x_batch_minusDELTA))/2.
    u_yy = ((u - 2.0*u_deltay + u_2deltay)/(self.DELTA**2)) + (tape3.gradient(ad_u_y, self.y_batch)-tape3.gradient(ad_u_y_delta, y_batch_minusDELTA))/2.
    v_xx = ((v - 2.0*v_deltax + v_2deltax)/(self.DELTA**2)) + (tape3.gradient(ad_v_x, self.x_batch)-tape3.gradient(ad_v_x_delta, x_batch_minusDELTA))/2.
    v_yy = ((v - 2.0*v_deltay + v_2deltay)/(self.DELTA**2)) + (tape3.gradient(ad_v_y, self.y_batch)-tape3.gradient(ad_v_y_delta, y_batch_minusDELTA))/2.
    p_x = ((p_pdeltax - p_deltax)/(2.*self.DELTA)) - (tape3.gradient(p_pdeltax, x_batch_plusDELTA) -2.0*tape3.gradient(p, self.x_batch)+ tape3.gradient(p_deltax, x_batch_minusDELTA))/8.
    p_y = ((p_pdeltay - p_deltay)/(2.*self.DELTA)) - (tape3.gradient(p_pdeltay, y_batch_plusDELTA) -2.0*tape3.gradient(p, self.y_batch)+ tape3.gradient(p_deltay, y_batch_minusDELTA))/8.
    del tape3, tape4
    return u,v,p,u_x,u_y,u_t,v_x,v_y,v_t,p_x,p_y,u_xx,u_yy,v_xx,v_yy
  
  @tf.function
  def LR_Annealing(self):
    
    with tf.GradientTape(persistent=True) as tape2:
      losses = self.Calculate_separate_losses()
      loss_eq = losses[0]+losses[1]
      loss_bd = losses[2]+losses[3]+losses[5]
      loss_dt = losses[4]
 
    grad_eq = tape2.gradient(loss_eq, self.model.trainable_variables, unconnected_gradients='zero')
    grad_bd = tape2.gradient(loss_bd, self.model.trainable_variables, unconnected_gradients='zero')
    grad_dt = tape2.gradient(loss_dt, self.model.trainable_variables, unconnected_gradients='zero')
    del tape2
    # tf.print('grad',grad_eq)
    mean_grad_eq = tf.reduce_max(tf.abs(tf.concat([tf.reshape(g, (-1,)) for g in grad_eq], axis=-1)))
    lambs_hat_bd = mean_grad_eq / (tf.reduce_mean(tf.abs(tf.concat([tf.reshape(g, (-1,)) for g in grad_bd], axis=-1)))+1e-12)
    lambs_hat_dt = mean_grad_eq / (tf.reduce_mean(tf.abs(tf.concat([tf.reshape(g, (-1,)) for g in grad_dt], axis=-1)))+1e-12)
    
    if tf.reduce_sum(self.LR_alpha) ==0:
      self.LR_alpha.assign(lambs_hat_dt)
      self.LR_beta.assign(lambs_hat_bd)
    
    self.LR_alpha.assign(self.EMA(lambs_hat_dt,self.LR_alpha,self.LR_decay))
    self.LR_beta.assign(self.EMA(lambs_hat_bd,self.LR_beta,self.LR_decay))
  
    loss = self.term_weights[0] * loss_eq + \
           self.term_weights[1] * self.LR_beta * loss_bd +\
           self.term_weights[2] * self.LR_alpha * loss_dt
    return loss
  
  @tf.function
  def DW_balance(self,losses):
    # calculate loss and losses
    self.lossmemory_dt.assign(self.EMA( (losses[4]) , self.lossmemory_dt, self.EMA_decay))
    self.lossmemory_bd.assign(self.EMA( (losses[2]+losses[3]+losses[5]) , self.lossmemory_bd, self.EMA_decay))

    # tf.print('teste',self.inter_count,'lossmemory_dt',self.lossmemory_dt,'alpha', self.alpha,'loss d,bd,eq =',
    #           self.term_weights[2]*self.alpha * (l5),'*',self.term_weights[1]*self.beta * (l3+l4+l6),
    #           '*', self.term_weights[0]*l1+l2)
    self.max_loss_eq.assign(tf.math.maximum(self.max_loss_eq, tf.math.abs(losses[0]+losses[1])))
    self.inter_count.assign_add(1) 
      
    if self.inter_count == self.weight_update:
      self.alpha_star.assign(tf.math.divide(self.max_loss_eq,
                                           self.lossmemory_dt))
      self.beta_star.assign(tf.math.divide(self.max_loss_eq,
                                           self.lossmemory_bd))
      
      self.alpha.assign(self.EMA(self.alpha_star,self.alpha,self.w_decay))
      self.beta.assign(self.EMA(self.beta_star,self.beta,self.w_decay))

      self.inter_count.assign(0)
      self.max_loss_eq.assign(0) 
     
    loss = self.term_weights[0] * (losses[0]+losses[1]) + \
      self.term_weights[1] * self.beta * (losses[2]+losses[3]+losses[5]) +\
        self.term_weights[2] * self.alpha * losses[4]
    return loss
  
  @tf.function
  def DW_ReLoBRaLo(self,losses):
    saudade = tf.random.normal([1],mean=1,stddev=self.rho_std,dtype=self.dtype)
    saudade  = tf.math.minimum(tf.math.maximum(saudade[0],0),1)    

    loss_eq = losses[0]+losses[1]
    loss_bd = losses[2]+losses[3]+losses[5]
    loss_dt = losses[4]
    losses = [loss_eq] + [loss_bd,loss_dt]
    
    if tf.reduce_sum(self.previus_loss) == 0:
      self.previus_loss.assign(losses)

    lambs_hat = tf.stop_gradient(tf.nn.softmax([losses[i]/(self.previus_loss[i]*self.T+1e-12) for i in range(len(losses))])*tf.cast(len(losses), dtype=self.dtype))
    lambs0_hat = tf.stop_gradient(tf.nn.softmax([losses[i]/(self.lamb_0[i]*self.T+1e-12) for i in range(len(losses))])*tf.cast(len(losses), dtype=self.dtype))
    
    if tf.reduce_sum(self.previus_lamb) == 0:
      self.previus_lamb.assign(lambs_hat)    
    
    lambs = [saudade*self.alpha_decay*self.previus_lamb[i] + (1-saudade)*self.alpha_decay*lambs0_hat[i] + (1-self.alpha_decay)*lambs_hat[i] for i in range(len(losses))]

    loss = tf.reduce_sum([lambs[i]*losses[i]*self.term_weights[i] for i in range(len(losses))])
    # tf.print('teste',lambs[0],'**',lambs[1],'**',lambs[2], '***', lambs[0]*losses[0],'*',lambs[1]*losses[1],'*',lambs[2]*losses[2],'*')

    # update previus
    self.previus_lamb.assign(lambs)
    self.previus_loss.assign(losses)
    if tf.reduce_sum(self.lamb_0) == 0:
      self.lamb_0.assign(lambs)

    return loss

  @tf.function
  def EMA(self,new,previous,decay):
    return (1-decay)*previous + decay*new

  @tf.function
  def summary(self):
    return self.model.summary()

  # The training function
  # @tf.function
  def fit(self, X_bd_vel, Y_bd_vel,X_bd_pre, Y_bd_pre,
          X_data,Y_data, tf_epochs=5000, batch_size = 128 ):

    self.logger.log_train_start(self)
    # Creating the tensors
    self.X_bd_vel = tf.convert_to_tensor(X_bd_vel, dtype=self.dtype)
    self.Y_bd_vel = tf.convert_to_tensor(Y_bd_vel, dtype=self.dtype)
    self.X_bd_pre = tf.convert_to_tensor(X_bd_pre, dtype=self.dtype)
    self.Y_bd_pre = tf.convert_to_tensor(Y_bd_pre, dtype=self.dtype)
    self.X_data = tf.convert_to_tensor(X_data, dtype=self.dtype)
    self.Y_data = tf.convert_to_tensor(Y_data, dtype=self.dtype)
    train_dataset =tf.data.Dataset.from_tensor_slices(self.X_pinn_train)
    self.x_batch = tf.Variable(tf.zeros(shape = [batch_size,1]), trainable=False, dtype=self.dtype)
    self.y_batch = tf.Variable(tf.zeros(shape = [batch_size,1]), trainable=False, dtype=self.dtype)
    self.t_batch = tf.Variable(tf.zeros(shape = [batch_size,1]), trainable=False, dtype=self.dtype)

    for epoch in range(tf_epochs):
      # batch step
      train_batchs = train_dataset.shuffle(self.X_pinn_train.shape[0],reshuffle_each_iteration = True).batch(batch_size).enumerate()
      for step, batch in train_batchs:
        batch = tf.convert_to_tensor(batch, dtype=self.dtype)
        self.x_batch[:batch.shape[0],].assign(batch[:, 0:1])
        self.y_batch[:batch.shape[0],].assign(batch[:, 1:2])
        if not self.steady:
          self.t_batch[:batch.shape[0],].assing(batch[:, 2:3])
        # Optimization step
        loss_value = self.train_step()
        
        self.logger.log_train_batch(step, loss_value, self.losses)
      self.logger.log_train_epoch(epoch, loss_value)
    self.logger.log_train_end(tf_epochs)
  
  # Train in tf graph mode
  @tf.function
  def train_step(self):
    
    loss_value, grads = self.f_grad()
    self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))
    # check graph mode
    # tf.print("Eager execution: {}".format(tf.executing_eagerly())) 
    return loss_value
    
  
  # @tf.function
  def predict(self, X_star):
    u_star = self.model(X_star,training=False)
    return u_star
  
  @tf.function
  def Sliced_Predict(self,X):
    Pred =  tf.cast(self.model(X,training=True), self.dtype)
    u = tf.slice(Pred,[0,0],[-1,1])
    v = tf.slice(Pred,[0,1],[-1,1])
    p = tf.slice(Pred,[0,2],[-1,1])
    return u,v,p
  
  def set_outside_points(self,points):
    self.X_outside =tf.convert_to_tensor(points, dtype=self.dtype)
    return
  
  def start_dynamic_weight(self,pinn_w = [1,1,1,1,1,1], dynamic_weight_method = 'NONE', term_weights = [1,1,1],
                         w_decay = 0.1, weight_update_step = 200, start = 1, EMA_decay = 0.04,
                         temperature = 1e-2, alpha_decay = 0.99, rho_std = 0.1,
                         LR_decay = 0.9):
    
    ## shold be included in init()
    

    self.pinn_w = tf.Variable(pinn_w, trainable = False, dtype=self.dtype)
    self.term_weights = tf.Variable(term_weights, trainable = False, dtype=self.dtype)
    self.dynamic_weight_method = tf.Variable(dynamic_weight_method, trainable = False, dtype = tf.string)
    ##
    self.w_decay = tf.Variable(w_decay, trainable = False)
    self.EMA_decay = tf.Variable(EMA_decay, trainable = False)
    self.weight_update = tf.Variable(weight_update_step, trainable = False,dtype=tf.int16)
    self.lossmemory_dt = tf.Variable(0,trainable=False, dtype=self.dtype)
    self.lossmemory_bd= tf.Variable(0,trainable=False, dtype=self.dtype)
    self.alpha_star  = tf.Variable(0,trainable=False, dtype=self.dtype)
    self.beta_star  = tf.Variable(0,trainable=False, dtype=self.dtype)
    self.alpha  = tf.Variable(start,trainable=False, dtype=self.dtype)
    self.beta  = tf.Variable(start,trainable=False, dtype=self.dtype)
    self.max_loss_eq  = tf.Variable(0,trainable=False, dtype=self.dtype)
    self.inter_count = tf.Variable(0, trainable=False, dtype= tf.int16)
    ##
    self.T = tf.Variable(temperature, trainable=False, dtype= self.dtype)
    self.previus_loss = tf.Variable([0,0,0],trainable=False, dtype=self.dtype)
    self.previus_lamb = tf.Variable([0,0,0],trainable=False, dtype=self.dtype)
    self.lamb_0 = tf.Variable([0,0,0],trainable=False, dtype=self.dtype)
    self.alpha_decay = tf.Variable(alpha_decay,trainable=False, dtype=self.dtype)
    self.rho_std = tf.Variable(rho_std,trainable=False, dtype=self.dtype)
    ##
    self.LR_decay = tf.Variable(LR_decay,trainable=False, dtype=self.dtype)
    self.LR_alpha  = tf.Variable(start,trainable=False, dtype=self.dtype)
    self.LR_beta  = tf.Variable(start,trainable=False, dtype=self.dtype)
    return
  
  def set_dynamic_weight(self,pinn_w = [1,1,1,1,1,1], dynamic_weight_method = 'NONE', term_weights = [1,1,1],
                            w_decay = 0.1, weight_update_step = 200, start = 1, EMA_decay = 0.4,
                            temperature = 1e-2, alpha_decay = 0.99, rho_std = 0.1,
                            LR_decay = 0.9):
    """  *  pinn_w  =>  weight for each part separately.
    order:[momentum , mass, vel bd,pressure bd, data, out_vel]
    
    - only one that works if dynamic weight is off (is_dynamic_weight = False)
    - 'influence the loss within each term, 
    for example increasing the relevance of the loss by the mass conservation equation 
    in relation of momentum conservation equation'
    
          *term_weights =>  weight for each term
    order: [equations, boundary conditions, data]
    terms are created by combining the parts:
      equation:  mass + momentum
      boundary:  vel bd + pressure bd + out_vel
      data:  data
      
    - influences only if dynamic_weight_method = 'balance'
    
    * w_decay -> moving average decay to update alpha and beta
    * weight_update_step -> frequency of update alpha and beta
    * start-> initial value of alpha and beta
    * EMA_decay -> decay of exponential moving average that store the average of loss_bd and loss_data
    
    relobralo ->>https://arxiv.org/abs/2110.09813
    
    T −→ ∞ recalibrates the softmax to output uniform values and thus all λˆ(t)i = 1.
    On the other hand, T −→ 0 essentially turns the softmax into an argmax function, with the scaling
    λˆ(t)i = k resulting for the term with the lowest relative progress and λˆ(t)i = 0 for all others.

    
    """
    self.pinn_w.assign(pinn_w)
    self.term_weights.assign(term_weights)
    self.dynamic_weight_method.assign(dynamic_weight_method)
    if self.dynamic_weight_method == 'balance':
      self.w_decay.assign(w_decay)
      self.EMA_decay.assign(EMA_decay)
      self.weight_update.assign(weight_update_step)
      self.lossmemory_dt.assign(0)
      self.lossmemory_bd.assign(0)
      self.alpha_star.assign(0)
      self.beta_star.assign(0)
      self.alpha.assign(start)
      self.beta.assign(start)
      self.max_loss_eq.assign(0)
      self.inter_count.assign(0)
    elif self.dynamic_weight_method == 'relobralo':
      self.T.assign(temperature)
      self.previus_loss.assign([0,0,0])
      self.previus_lamb.assign([0,0,0])
      self.lamb_0.assign([0,0,0])
      self.alpha_decay.assign(alpha_decay)
      self.rho_std.assign(rho_std)
    elif self.dynamic_weight_method == 'LR_annealing':
      self.LR_alpha.assign(start)
      self.LR_beta.assign(start)
      self.LR_decay.assign(LR_decay)
    return

class Logs(object):
  def __init__(self, frequency_epoch=10,frequency_batch=10):
    print("TensorFlow version: {}".format(tf.__version__))
    print("Eager execution: {}".format(tf.executing_eagerly()))
    print("GPU-accerelated: {}".format(tf.config.list_physical_devices('GPU')))

    self.start_time = time.time()
    self.frequency_epoch = frequency_epoch
    self.frequency_batch = frequency_batch
    self.error_fn2_flag = False
    self.loss = []
    self.error = []

  def __get_elapsed(self):
    return datetime.fromtimestamp(time.time() - self.start_time).strftime("%M:%S")

  def set_error_fn(self, error_fn,name='error'):
    self.error_fn = error_fn
    self.error_fn_name = name
    
  def set_error_fn2(self, error_fn,name='error2'):
    self.error_fn2 = error_fn
    self.error_fn2_name = name
    self.error_fn2_flag = True
   
  def log_train_start(self, model):
    print("\n ADAM Training started")
    print("================")
    self.model = model
    print(self.model.summary())
    print("\nTotal_Loss * 1:Momentum 2:Mass 3:boundary_vel 4:boundary_pre 5:Data 6:boundary_out_vel")

  def log_train_epoch(self, epoch, loss, custom=""):
    if tf.math.floormod(epoch , self.frequency_epoch) == 0:
      error = self.error_fn()
      if self.error_fn2_flag:
        error2 = self.error_fn2()
        self.error.append([error,error2])
        print(f"ADAM epoch = {epoch:4d}  elapsed = {self.__get_elapsed()}  loss = {loss:.4e}  {self.error_fn_name} = {error:.4e} {self.error_fn2_name} = {error2:.2e} " + custom)
      else:  
        self.error.append([error])
        print(f"ADAM epoch = {epoch:4d}  elapsed = {self.__get_elapsed()}  loss = {loss:.4e}  {self.error_fn_name} = {error:.4e} " + custom)
        print("Total_Loss * 1:Momentum 2:Mass 3:boundary_vel 4:boundary_pre 5:Data 6:boundary_out_vel")


  def log_train_batch(self, batch, loss, losses, custom=""):
    if tf.math.floormod(batch , self.frequency_batch) == 0:
      self.loss.append([losses[0].numpy(),losses[1].numpy(),losses[2].numpy(),losses[3].numpy(),losses[4].numpy(),losses[5].numpy()])
      print(f"batch = {batch:3d}  elapsed = {self.__get_elapsed()}  loss = {loss:.4e} * {losses[0]:.2e} {losses[1]:.2e} {losses[2]:.2e} {losses[3]:.2e} {losses[4]:.2e} {losses[5]:.2e}" + custom)

  def log_train_end(self, epoch, custom=""):
    print("==================")
    print(f"ADAM Training finished (epoch {epoch}): duration = {self.__get_elapsed()}  error = {self.error_fn():.4e}  " + custom)

  def save(self,path_name):
    error = np.zeros((np.array(self.loss).shape[0],np.shape(self.error)[1]))
    error[0:len(np.array(self.error)),:] = np.array(self.error)
    np.savetxt(path_name,np.concatenate((np.array(self.loss),error),axis=1), delimiter=",")


"""TensorFlow interface for TensorFlow Probability optimizers including lbfgs_minimize."""
import tensorflow_probability as tfp

class LossAndFlatGradient:
    """A helper class to create a function required by tfp.optimizer.lbfgs_minimize.
    Args:
        trainable_variables: Trainable variables.
        build_loss: A function to build the loss function expression.
    """

    def __init__(self, trainable_variables, build_loss):
        self.trainable_variables = trainable_variables
        self.build_loss = build_loss

        # Shapes of all trainable parameters
        self.shapes = tf.shape_n(trainable_variables)
        self.n_tensors = len(self.shapes)

        # Information for tf.dynamic_stitch and tf.dynamic_partition later
        count = 0
        self.indices = []  # stitch indices
        self.partitions = []  # partition indices
        for i, shape in enumerate(self.shapes):
            n = np.product(shape)
            self.indices.append(
                tf.reshape(tf.range(count, count + n, dtype=tf.int32), shape)
            )
            self.partitions.extend([i] * n)
            count += n
        self.partitions = tf.constant(self.partitions)

    @tf.function
    def __call__(self, weights_1d):
        """A function that can be used by tfp.optimizer.lbfgs_minimize.
        Args:
           weights_1d: a 1D tf.Tensor.
        Returns:
            A scalar loss and the gradients w.r.t. the `weights_1d`.
        """
        # check graph mode
        # tf.print("Eager execution: {}".format(tf.executing_eagerly()))
        
        # Set the weights
        self.set_flat_weights(weights_1d)
        with tf.GradientTape() as tape:
            # Calculate the loss
            loss = self.build_loss()
        # Calculate gradients and convert to 1D tf.Tensor
        grads = tape.gradient(loss, self.trainable_variables)
        grads = tf.dynamic_stitch(self.indices, grads)
        return loss, grads
      
    def set_flat_weights(self, weights_1d):
        """Sets the weights with a 1D tf.Tensor.
        Args:
            weights_1d: a 1D tf.Tensor representing the trainable variables.
        """
        weights = tf.dynamic_partition(weights_1d, self.partitions, self.n_tensors)
        for i, (shape, param) in enumerate(zip(self.shapes, weights)):
            self.trainable_variables[i].assign(tf.reshape(param, shape))

    def to_flat_weights(self, weights):
        """Returns a 1D tf.Tensor representing the `weights`.
        Args:
            weights: A list of tf.Tensor representing the weights.
        Returns:
            A 1D tf.Tensor representing the `weights`.
        """
        return tf.dynamic_stitch(self.indices, weights)

def set_LBFGS_options(num_correction_pairs=100, f_relative_tolerance=0, parallel_iterations = 1,
                      tolerance=1e-8, max_iterations=15000, max_line_search_iterations=50 ):
    """Sets the hyperparameters of L-BFGS.
    The L-BFGS optimizer used in each backend:
    I find empirically that torch.optim.LBFGS and scipy.optimize.minimize are better than
    tfp.optimizer.lbfgs_minimize in terms of the final loss value.
    Args:
       `num_correction_pairs`
            The maximum number of variable metric corrections used to define the limited
            memory matrix. (The limited memory BFGS method does not store the full
            hessian but uses this many terms in an approximation to it.)  
         `f_relative_tolerance`
            The iteration stops when `(f^k - f^{k+1})/max{|f^k|,|f^{k+1}|,1} <= ftol`.
       `tolerance` (tfp)
            The iteration will stop when `max{|proj g_i | i = 1, ..., n} <= gtol` where
            `pg_i` is the i-th component of the projected gradient.
       `max_iterations` (tfp),
            Maximum number of iterations.
       `max_line_search_iterations` (tfp).
            Maximum number of line search steps (per iteration).
       'parralel_iteration'
             Positive integer. The number of iterations allowed to run in parallel.
    Warning:
        If L-BFGS stops earlier than expected, set the default float type to 'float64':
        .. code-block:: python
            dde.config.set_default_float("float64")
    """
    LBFGS_options = {}
    LBFGS_options["maxcor"] = num_correction_pairs
    LBFGS_options["ftol"] = f_relative_tolerance
    LBFGS_options["gtol"] = tolerance
    LBFGS_options["maxiter"] = max_iterations
    LBFGS_options["maxls"] = max_line_search_iterations
    LBFGS_options["parallel"] = parallel_iterations
    return LBFGS_options
  
def lbfgs_minimize(trainable_variables, build_loss, 
                   LBFGS_options = set_LBFGS_options(), previous_optimizer_results=None):
    """TensorFlow interface for tfp.optimizer.lbfgs_minimize.
    Args:
        trainable_variables: Trainable variables, also used as the initial position.
        build_loss: A function to build the loss function expression.
        previous_optimizer_results
    """
    print("\n LBFGS Training started")
    print("================")
    func = LossAndFlatGradient(trainable_variables, build_loss)
    initial_position = None
    if previous_optimizer_results is None:
        initial_position = func.to_flat_weights(trainable_variables)
    results = tfp.optimizer.bfgs_minimize(
        func,
        initial_position=initial_position,
        # previous_optimizer_results=previous_optimizer_results,
        # num_correction_pairs=LBFGS_options["maxcor"],
        tolerance=LBFGS_options["gtol"],
        x_tolerance=0,
        f_relative_tolerance=LBFGS_options["ftol"],
        max_iterations=LBFGS_options["maxiter"],
        max_line_search_iterations=LBFGS_options["maxls"],
        parallel_iterations = LBFGS_options["parallel"],
    )
    # The final optimized parameters are in results.position.
    # Set them back to the variables.
    func.set_flat_weights(results.position)
    return 
